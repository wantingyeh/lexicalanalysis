{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4f7fefd-a5a7-427c-9136-5cea99c8adba",
   "metadata": {},
   "source": [
    "# Random sampling\n",
    "\n",
    "purpose: random sampling the word tokens from the corpora, so we have the equal sampling size \\\n",
    "Looping through different sample sizes: \\\n",
    "from 100 to 2000, with a step = 100 \\\n",
    "so, we can have varying sample sizes for different conditions/groups\n",
    "\n",
    "## with interjections\n",
    "\n",
    "from 100 to 2000, with a step = 100 \n",
    "- OVERALL_TXT = \"clean_parent_all.txt\" (total words: 7296)\n",
    "- CV_TXT = \"CV_clean_overall_condition.txt\" (total words: 3992)\n",
    "- DG_TXT = \"DG_clean_overall_condition.txt\" (total words: 3279)\n",
    "- CONTI_TXT = \"contingency_clean_overall_contingency.txt\" (total words: 2424)\n",
    "- NONCON_TXT = \"non-contingency_clean_overall_contingency.txt\"  (total words: 4845) \n",
    "\n",
    "\n",
    "from 100 to 900, with a step = 100 \n",
    "- CV_C_TXT = \"CV-1_clean_overall_contigent\" (total words: 2558)\n",
    "- CV_NC_TXT = \"CV-0_clean_overall_Ncontigent\" (total words: 1434) \n",
    "- DG_C_TXT = \"DG-1_clean_overall_contigent\" (total words: 2289)\n",
    "- DG_NC_TXT = \"DG-0_clean_overall_Ncontigent\" (total words: 990)\n",
    "\n",
    "## without interjections & sound-like words\n",
    "\n",
    "- OVERALL_TXT = \"clean_pooling_all_clean_woint.txt\" (total words: 6816)\n",
    "- CV_TXT = \"CV_pooling_clean_woint.txt\" (total words: 3725)\n",
    "- DG_TXT = \"DG_pooling_clean_woint.txt\" (total words: 3065)\n",
    "- CONTI_TXT = \"1_C_pooling_clean_woint.txt\" (total words: 2245)\n",
    "- NONCON_TXT = \"0_NC_pooling_clean_woint.txt\"  (total words: 4541) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f693d9f-cf50-4a5e-9f00-e0702610fac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37149328-fe25-40a4-bee7-777e635cd324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This chunck is for with interjections\n",
    "FOLDER_PATH = \"C:/Users/USER/PycharmProjects/UniqueWordCalculator/clean_data\"\n",
    "OVERALL_TXT = \"clean_all_text.txt\"\n",
    "CV_TXT = \"CV_clean_pooling.txt\"\n",
    "DG_TXT = \"DG_clean_pooling.txt\"\n",
    "CONTI_TXT = \"1_C_clean_pooling.txt\"\n",
    "NONCON_TXT = \"0_NC_clean_pooling.txt\"\n",
    "CV_C_TXT = \"CV-1_clean_overall_contigent.txt\" \n",
    "CV_NC_TXT = \"CV-0_clean_overall_Ncontigent.txt\" \n",
    "DG_C_TXT = \"DG-1_clean_overall_contigent.txt\" \n",
    "DG_NC_TXT = \"DG-0_clean_overall_Ncontigent.txt\" \n",
    "OUTPUT_PATH = \"C:/Users/USER/PycharmProjects/UniqueWordCalculator/output/inc_interjections\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2805bae0-c485-46f6-ad9d-eae8863dbeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this chunk is for without interjections\n",
    "FOLDER_PATH = \"C:/Users/USER/PycharmProjects/UniqueWordCalculator/parent-condition/pooling-data/wo_interjections\"\n",
    "OVERALL_TXT = \"clean_pooling_all_clean_woint.txt\"\n",
    "CV_TXT = \"CV_pooling_clean_woint.txt\"\n",
    "DG_TXT = \"DG_pooling_clean_woint.txt\"\n",
    "CONTI_TXT = \"1_C_pooling_clean_woint.txt\"\n",
    "NONCON_TXT = \"0_NC_pooling_clean_woint.txt\"\n",
    "OUTPUT_PATH = \"C:/Users/USER/PycharmProjects/UniqueWordCalculator/output/wo_interjections\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3d7b61a-f1ea-4b62-ad29-d1f68441a457",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_CON = CV_TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "185e2f90-9867-4ebb-a89b-3c2c77b1021f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/USER/PycharmProjects/UniqueWordCalculator/parent-condition/pooling-data/wo_interjections/CV_pooling_clean_woint.txt_freqrank.txt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILENAME = FOLDER_PATH + \"/\" + CV_TXT \n",
    "FILENAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a3c9c66a-3b26-4dda-9fdc-a66f05b2e565",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FILENAME) as all_file:\n",
    "    all_content = all_file.readlines()\n",
    "#     all_content = [token.strip('\\n') for token in all_content]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6067374b-2222-44e7-a1f1-db1f8a868b0b",
   "metadata": {},
   "source": [
    "# iteration for 100 times\n",
    "\n",
    "1. loop from starting size to end size with steps\n",
    "2. repeat this method for 100 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b2a69c0d-7f0b-4dd3-931e-78305e147e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "STARTING_SIZE = 100\n",
    "ENDING_SIZE = 905\n",
    "STEP = 100\n",
    "iter_count = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "030fe34b-7a17-43c2-85cd-91fb07adecd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIXED_NUM_RANGE = list(range(STARTING_SIZE, ENDING_SIZE, STEP))  #to data frame\n",
    "# FIXED_NUM_RANGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d7744de-381e-49c1-b6c6-41a0dbaf3145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenth of the new_word_list: 900\n"
     ]
    }
   ],
   "source": [
    "# iteration for 100 times\n",
    "# random sampling from start size to end size with steps\n",
    "\n",
    "\n",
    "new_word_list = []\n",
    "is_iter = True\n",
    "repos = 0\n",
    "\n",
    "while is_iter:\n",
    "    # randomly sampling from 100 to 2000, with step 100\n",
    "    for i in range(STARTING_SIZE, ENDING_SIZE, STEP):\n",
    "        new_word = random.sample(all_content, i)\n",
    "        new_word = \"\".join([word for word in new_word])\n",
    "        new_word = new_word.split()\n",
    "        new_word_list.append(new_word)\n",
    "    repos += 1\n",
    "    if repos == iter_count:\n",
    "        is_iter = False\n",
    "\n",
    "print(f\"lenth of the new_word_list: {len(new_word_list)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ca947590-1d63-4f02-8bb2-6b24a802bfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['see', 'hide', 'hello', 'boo', 'do', 'to', 'be', 'okay', 'peekaboo', 'you', 'peekaboo', 'peekaboo', 'I', 'can', 'mother', 'it', 'hide', 'at', 'be', 'peekaboo', 'he', 'as', 'mother', 'it', 'play', 'peekaboo', 'where', 'this', 'you', 'can', 'see', 'peek', 'boo', 'your', 'sweetheart', 'on', 'cover', 'good', 'boo', 'here', 'chair', 'what', 'to', 'where', 'be', 'tv', 'boo', 'ready', 'play', 'hello', 'look', 'hey', 'boo', 'he', 'mother', 'have', 'where', 'it', 'be', 'peekaboo', 'be', 'hide', 'where', 'childname', 'peekaboo', 'now', 'be', 'where', 'ready', 'on', 'be', 'you', 'boo', 'everything', 'get', 'peekaboo', 'boo', 'whoa', 'she', 'be', 'see', 'be', 'can', 'will', 'be', 'do', 'ah', 'mother', 'childname', 'be', 'father', 'you', 'it', 'where', 'look', 'you', 'hand', 'where', 'eye', 'where', 'different', 'hide', 'hi', 'and', 'uh', 'you', 'not', 'hide', 'boo', 'do', 'you', 'be', 'mother', 'mother', 'computer', 'be', 'go', 'be', 'peekaboo', 'face', 'mother', 'you', 'see', 'nicely', 'where', 'boo', 'you', 'I', 'she', 'be', 'he', 'you', 'see', 'be', 'be', 'mother', 'again', 'aw', 'can', 'about', 'mm', 'where', 'go', 'be', 'hello', 'peekaboo', 'peekaboo', 'peekaboo', 'see', 'where', 'boo', 'see', 'mother', 'just', 'where', 'be', 'mother', 'peekaboo', 'it', 'can', 'hi', 'peekaboo', 'your', 'be', 'your', 'go', 'listening', 'be', 'peekaboo', 'peekaboo', 'boo', 'where', 'see', 'eye', 'go', 'all', 'play', 'where', 'peekaboo', 'cover', 'I', 'yay', 'see', 'be', 'be', 'screen', 'yay', 'be', 'hand', 'be', 'do', 'sit', 'where', 'boo', 'be', 'mother', 'boo', 'on', 'hi', 'no']\n"
     ]
    }
   ],
   "source": [
    "# check word list \n",
    "print(new_word_list[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e8810546-a65d-4905-a3c0-68fabf142956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenth of the new_word_list: 900\n",
      "lenth of the unique_list: 900\n"
     ]
    }
   ],
   "source": [
    "# store unique words into a list\n",
    "\n",
    "unique_list = []\n",
    "\n",
    "for n in range(len(new_word_list)):\n",
    "    unique_list.append([])\n",
    "    for word in new_word_list[n]:\n",
    "        if word not in unique_list[n]:\n",
    "            unique_list[n].append(word)\n",
    "\n",
    "\n",
    "print(f\"lenth of the new_word_list: {len(new_word_list)}\")\n",
    "print(f\"lenth of the unique_list: {len(unique_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fd9c3094-c3e8-469b-b211-19ac732cc136",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_count_list = []\n",
    "for unique_count in range(len(unique_list)):\n",
    "    count = len(unique_list[unique_count])\n",
    "    unique_count_list.append(count)\n",
    "    \n",
    "# print(unique_count_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61f362e1-cdde-4aed-9ab3-d62a820b1a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(FIXED_NUM_RANGE*iter_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0f354326-6017-414a-bc2f-d770835fb74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampling_size</th>\n",
       "      <th>num_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>400</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>500</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>600</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>700</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>800</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>900</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sampling_size  num_unique\n",
       "0              100          45\n",
       "1              200          65\n",
       "2              300          74\n",
       "3              400          90\n",
       "4              500          87\n",
       "..             ...         ...\n",
       "895            500          95\n",
       "896            600          95\n",
       "897            700         115\n",
       "898            800         121\n",
       "899            900         123\n",
       "\n",
       "[900 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dic = {\n",
    "    \"sampling_size\":FIXED_NUM_RANGE*iter_count,\n",
    "    \"num_unique\": unique_count_list\n",
    "}\n",
    "\n",
    "pd.DataFrame(sample_dic)\n",
    "df = pd.DataFrame(sample_dic)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1143f962-486f-40ec-9901-e8b4058b140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"{OUTPUT_PATH}/{CURRENT_CON}_samplingsize_iterate.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
